{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143e7268",
   "metadata": {},
   "source": [
    "# 04 - ML Pipeline: Exploration, Feature Engineering & Classification\n",
    "\n",
    "**Complete Machine Learning Workflow** using Silver_ML data:\n",
    "\n",
    "1. **SQL Exploration**: Analyze flight patterns and statistics\n",
    "2. **Feature Engineering**: Create ML-ready features with window functions\n",
    "3. **Classification**: Random Forest for flight phase prediction\n",
    "\n",
    "**Note**: Silver_ML data is generated by 02_Unified_Pipeline. Ensure it's running first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from typing import List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import (\n",
    "    col, lag, avg, stddev, row_number, when, sqrt, pow, lit, min as spark_min,\n",
    "    sum as spark_sum, count, broadcast\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, IndexToString\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "sys.path.insert(0, '/home/jovyan/work')\n",
    "from config import get_s3_path, create_spark_session\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SILVER_PATH: str = get_s3_path(\"silver\", \"flights\")\n",
    "SILVER_ML_PATH: str = get_s3_path(\"silver\", \"flights_ml\")\n",
    "GOLD_MODEL_PATH: str = get_s3_path(\"gold\", \"models\", \"rf_flight_phase\")\n",
    "GOLD_PREDICTIONS_PATH: str = get_s3_path(\"gold\", \"predictions\", \"flight_phase\")\n",
    "AIRPORTS_CSV: str = \"./data/airports.csv\"\n",
    "\n",
    "logger.info(f\"Silver: {SILVER_PATH}\")\n",
    "logger.info(f\"Silver_ML: {SILVER_ML_PATH}\")\n",
    "logger.info(f\"Model: {GOLD_MODEL_PATH}\")\n",
    "logger.info(f\"Predictions: {GOLD_PREDICTIONS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c720aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark: SparkSession = create_spark_session(\n",
    "    \"MLPipeline\",\n",
    "    extra_packages=[\"org.apache.spark:spark-mllib_2.12:3.5.3\"],\n",
    "    shuffle_partitions=6\n",
    ")\n",
    "\n",
    "logger.info(\"Spark session initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a60cff",
   "metadata": {},
   "source": [
    "## Part 1: SQL Exploration\n",
    "\n",
    "Analyze flight patterns using SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver: DataFrame = spark.read.format(\"delta\").load(SILVER_PATH)\n",
    "df_silver.createOrReplaceTempView(\"flights\")\n",
    "logger.info(f\"Loaded {df_silver.count():,} records from Silver layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1805fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        origin_country,\n",
    "        COUNT(*) AS observations,\n",
    "        COUNT(DISTINCT icao24) AS unique_aircraft,\n",
    "        ROUND(AVG(altitude_meters), 2) AS avg_altitude_m,\n",
    "        ROUND(AVG(velocity_kmh), 2) AS avg_velocity_kmh,\n",
    "        ROUND(MIN(velocity_kmh), 2) AS min_velocity,\n",
    "        ROUND(MAX(velocity_kmh), 2) AS max_velocity\n",
    "    FROM flights\n",
    "    WHERE origin_country IS NOT NULL\n",
    "    GROUP BY origin_country\n",
    "    ORDER BY observations DESC\n",
    "    LIMIT 15\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ebd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE WHEN on_ground = true THEN 'ON_GROUND' ELSE 'IN_FLIGHT' END AS status,\n",
    "        COUNT(*) AS count,\n",
    "        COUNT(DISTINCT icao24) AS unique_aircraft,\n",
    "        ROUND(AVG(velocity_kmh), 2) AS avg_velocity,\n",
    "        ROUND(AVG(altitude_meters), 2) AS avg_altitude\n",
    "    FROM flights\n",
    "    GROUP BY on_ground\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN altitude_meters IS NULL THEN 'NULL'\n",
    "            WHEN altitude_meters < 1000 THEN '0-1000m'\n",
    "            WHEN altitude_meters < 5000 THEN '1000-5000m'\n",
    "            WHEN altitude_meters < 10000 THEN '5000-10000m'\n",
    "            WHEN altitude_meters < 15000 THEN '10000-15000m'\n",
    "            ELSE '15000m+'\n",
    "        END AS altitude_range,\n",
    "        COUNT(*) AS count,\n",
    "        ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) AS percentage\n",
    "    FROM flights\n",
    "    GROUP BY altitude_range\n",
    "    ORDER BY count DESC\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        icao24,\n",
    "        callsign,\n",
    "        origin_country,\n",
    "        CAST(event_timestamp AS STRING) AS timestamp,\n",
    "        altitude_meters,\n",
    "        LAG(altitude_meters) OVER (PARTITION BY icao24 ORDER BY event_timestamp) AS prev_altitude,\n",
    "        CAST(altitude_meters - LAG(altitude_meters) OVER (PARTITION BY icao24 ORDER BY event_timestamp) AS INT) AS altitude_change,\n",
    "        velocity_kmh,\n",
    "        ROUND(AVG(altitude_meters) OVER (PARTITION BY icao24 ORDER BY event_timestamp ROWS BETWEEN 5 PRECEDING AND CURRENT ROW), 2) AS rolling_avg_altitude,\n",
    "        RANK() OVER (PARTITION BY origin_country ORDER BY velocity_kmh DESC) AS velocity_rank_in_country,\n",
    "        ROW_NUMBER() OVER (PARTITION BY icao24 ORDER BY event_timestamp) AS observation_num\n",
    "    FROM flights\n",
    "    WHERE icao24 IS NOT NULL AND altitude_meters IS NOT NULL AND event_timestamp IS NOT NULL\n",
    "    ORDER BY icao24, event_timestamp\n",
    "    LIMIT 25\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver.select(\n",
    "    \"icao24\", \"callsign\", \"origin_country\", \"latitude\", \"longitude\",\n",
    "    \"altitude_meters\", \"velocity_kmh\", \"on_ground\", \"event_timestamp\"\n",
    ").limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2bdd11",
   "metadata": {},
   "source": [
    "## Part 2: Check Silver_ML Availability\n",
    "\n",
    "Verify that the unified pipeline has generated Silver_ML features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_ml: DataFrame = spark.read.format(\"delta\").load(SILVER_ML_PATH)\n",
    "    has_ml_data: bool = True\n",
    "    logger.info(f\"Loaded {df_ml.count():,} ML-enriched records from Silver_ML\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Silver_ML not available: {str(e)}\")\n",
    "    has_ml_data: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ccb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_ml_data:\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            flight_phase,\n",
    "            COUNT(*) AS count,\n",
    "            COUNT(DISTINCT icao24) AS unique_aircraft,\n",
    "            ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) AS percentage\n",
    "        FROM flights_ml\n",
    "        WHERE flight_phase IS NOT NULL\n",
    "        GROUP BY flight_phase\n",
    "        ORDER BY count DESC\n",
    "    \"\"\").show(truncate=False)\n",
    "    \n",
    "    df_ml.select(\n",
    "        \"icao24\", \"flight_phase\", \"altitude_meters\", \"velocity_kmh\",\n",
    "        \"altitude_change\", \"velocity_change\", \"rolling_avg_altitude\",\n",
    "        \"rolling_std_altitude\", \"rolling_avg_velocity\"\n",
    "    ).filter(col(\"flight_phase\").isNotNull()).limit(10).show(truncate=False)\n",
    "else:\n",
    "    logger.warning(\"Skipping ML training (Silver_ML not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef450a0",
   "metadata": {},
   "source": [
    "## Part 3: Feature Engineering & Preparation\n",
    "\n",
    "Prepare features for Random Forest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_ml_data:\n",
    "    FEATURE_COLUMNS: List[str] = [\n",
    "        \"altitude_meters\",\n",
    "        \"velocity_kmh\",\n",
    "        \"altitude_change\",\n",
    "        \"velocity_change\",\n",
    "        \"observation_rank\",\n",
    "        \"rolling_avg_altitude\",\n",
    "        \"rolling_std_altitude\",\n",
    "        \"rolling_avg_velocity\"\n",
    "    ]\n",
    "    \n",
    "    logger.info(f\"Using {len(FEATURE_COLUMNS)} features for classification\")\n",
    "    \n",
    "    df_train_raw = df_ml.filter(\n",
    "        (col(\"flight_phase\").isNotNull()) &\n",
    "        (col(\"altitude_meters\").isNotNull()) &\n",
    "        (col(\"velocity_kmh\").isNotNull())\n",
    "    ).cache()\n",
    "    \n",
    "    logger.info(f\"Prepared {df_train_raw.count():,} training records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea4ea9",
   "metadata": {},
   "source": [
    "## Part 4: Random Forest Classification\n",
    "\n",
    "Train and evaluate Random Forest model for flight phase prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df25c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_ml_data and df_train_raw.count() > 0:\n",
    "    label_indexer = StringIndexer(\n",
    "        inputCol=\"flight_phase\",\n",
    "        outputCol=\"label\",\n",
    "        handleInvalid=\"skip\"\n",
    "    )\n",
    "    \n",
    "    vector_assembler = VectorAssembler(\n",
    "        inputCols=FEATURE_COLUMNS,\n",
    "        outputCol=\"features_raw\",\n",
    "        handleInvalid=\"skip\"\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler(\n",
    "        inputCol=\"features_raw\",\n",
    "        outputCol=\"features\",\n",
    "        withStd=True,\n",
    "        withMean=False\n",
    "    )\n",
    "    \n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        labelCol=\"label\",\n",
    "        featuresCol=\"features\",\n",
    "        numTrees=100,\n",
    "        maxDepth=12,\n",
    "        maxBins=32,\n",
    "        seed=42,\n",
    "        numPartitions=4\n",
    "    )\n",
    "    \n",
    "    label_converter = IndexToString(\n",
    "        inputCol=\"prediction\",\n",
    "        outputCol=\"predicted_label\",\n",
    "        labels=label_indexer.fit(df_train_raw).labels\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(stages=[\n",
    "        label_indexer,\n",
    "        vector_assembler,\n",
    "        scaler,\n",
    "        rf_classifier,\n",
    "        label_converter\n",
    "    ])\n",
    "    \n",
    "    logger.info(\"ML pipeline constructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a085f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_ml_data and df_train_raw.count() > 0:\n",
    "    train_df, test_df = df_train_raw.randomSplit([0.8, 0.2], seed=42)\n",
    "    \n",
    "    logger.info(f\"Train: {train_df.count():,} | Test: {test_df.count():,}\")\n",
    "    \n",
    "    model = pipeline.fit(train_df)\n",
    "    logger.info(\"Random Forest trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e4223",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_ml_data and df_train_raw.count() > 0:\n",
    "    predictions = model.transform(test_df)\n",
    "    \n",
    "    evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"accuracy\"\n",
    "    )\n",
    "    \n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"f1\"\n",
    "    )\n",
    "    \n",
    "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "    f1_score = evaluator_f1.evaluate(predictions)\n",
    "    \n",
    "    logger.info(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "    logger.info(f\"Model F1 Score: {f1_score:.4f}\")\n",
    "    \n",
    "    predictions.select(\"flight_phase\", \"predicted_label\", \"probability\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_ml_data and df_train_raw.count() > 0:\n",
    "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "    \n",
    "    predictions_eval = model.transform(test_df)\n",
    "    \n",
    "    evaluators: dict = {\n",
    "        \"accuracy\": MulticlassClassificationEvaluator(\n",
    "            labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    "        ),\n",
    "        \"f1\": MulticlassClassificationEvaluator(\n",
    "            labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    "        ),\n",
    "        \"weightedPrecision\": MulticlassClassificationEvaluator(\n",
    "            labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    "        ),\n",
    "        \"weightedRecall\": MulticlassClassificationEvaluator(\n",
    "            labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    metrics_dict: dict = {name: evaluator.evaluate(predictions_eval) \n",
    "                          for name, evaluator in evaluators.items()}\n",
    "    \n",
    "    for metric_name, metric_value in metrics_dict.items():\n",
    "        logger.info(f\"{metric_name}: {metric_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd311da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_ml_data and df_train_raw.count() > 0:\n",
    "    rf_model = model.stages[3]\n",
    "    importances = rf_model.featureImportances.toArray()\n",
    "    \n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        \"feature\": FEATURE_COLUMNS,\n",
    "        \"importance\": importances\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "    \n",
    "    logger.info(\"Feature Importance (Top 10):\")\n",
    "    for idx, row in feature_importance_df.head(10).iterrows():\n",
    "        logger.info(f\"  {row['feature']:30} {row['importance']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f930f963",
   "metadata": {},
   "source": [
    "## Part 5: Save Model & Predictions\n",
    "\n",
    "Persist model and predictions to Gold layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23db790",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_ml_data and df_train_raw.count() > 0:\n",
    "    try:\n",
    "        model.write().overwrite().save(GOLD_MODEL_PATH)\n",
    "        logger.info(f\"Model persisted to {GOLD_MODEL_PATH}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Model save failed: {str(e)}\")\n",
    "    \n",
    "    predictions_to_save = predictions.select(\n",
    "        \"event_timestamp\",\n",
    "        \"icao24\",\n",
    "        \"callsign\",\n",
    "        \"origin_country\",\n",
    "        \"flight_phase\",\n",
    "        \"predicted_label\",\n",
    "        col(\"probability\").cast(\"string\").alias(\"confidence\"),\n",
    "        \"altitude_meters\",\n",
    "        \"velocity_kmh\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        predictions_to_save.write.format(\"delta\").mode(\"overwrite\").save(GOLD_PREDICTIONS_PATH)\n",
    "        logger.info(f\"Predictions persisted to {GOLD_PREDICTIONS_PATH}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Predictions save failed: {str(e)}\")\n",
    "else:\n",
    "    logger.info(\"ML training skipped (insufficient data or Silver_ML unavailable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c254a7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook completed three ML tasks:\n",
    "\n",
    "1. **SQL Exploration**: Analyzed flight patterns by country, altitude, status, and trajectory\n",
    "2. **Feature Engineering**: Verified Silver_ML features (temporal, rolling statistics, flight phases)\n",
    "3. **Classification**: Trained Random Forest model to predict flight phases\n",
    "\n",
    "**Output artifacts:**\n",
    "- `GOLD_MODEL_PATH`: Trained model (PipelineModel)\n",
    "- `GOLD_PREDICTIONS_PATH`: Test set predictions with confidence scores\n",
    "\n",
    "**Key insights:**\n",
    "- Feature importance shows which flight characteristics best predict phase\n",
    "- Confusion matrix reveals classification strengths/weaknesses\n",
    "- Model accuracy indicates quality of flight phase predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
