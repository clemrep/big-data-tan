{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Streaming Bronze\n",
    "\n",
    "Ingestion des donnÃ©es brutes depuis Kafka vers la couche Bronze (Delta Lake)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:20:13.589949Z",
     "start_time": "2026-01-19T16:19:26.115540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration chargÃ©e depuis .env\n",
      ":: loading settings :: url = jar:file:/opt/conda/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      "org.apache.spark#spark-hadoop-cloud_2.12 added as a dependency\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f5492da6-1898-48e3-b9cb-92c2b00e3752;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound org.apache.spark#spark-hadoop-cloud_2.12;3.5.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound com.google.cloud.bigdataoss#gcs-connector;hadoop3-2.2.14 in central\n",
      "\tfound joda-time#joda-time;2.12.5 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.15.2 in central\n",
      "\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.15.2 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.14 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.16 in central\n",
      "\tfound commons-codec#commons-codec;1.16.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.4 in central\n",
      "\tfound com.microsoft.azure#azure-storage;7.0.1 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.0.0 in central\n",
      "\tfound com.google.guava#guava;14.0.1 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.apache.hadoop#hadoop-cloud-storage;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-aliyun;3.3.4 in central\n",
      "\tfound com.aliyun.oss#aliyun-sdk-oss;3.13.0 in central\n",
      "\tfound org.jdom#jdom2;2.0.6 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound stax#stax-api;1.0.1 in central\n",
      "\tfound com.aliyun#aliyun-java-sdk-core;4.5.10 in central\n",
      "\tfound com.google.code.gson#gson;2.8.9 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.11 in central\n",
      "\tfound org.ini4j#ini4j;0.5.4 in central\n",
      "\tfound io.opentracing#opentracing-api;0.33.0 in central\n",
      "\tfound io.opentracing#opentracing-util;0.33.0 in central\n",
      "\tfound io.opentracing#opentracing-noop;0.33.0 in central\n",
      "\tfound com.aliyun#aliyun-java-sdk-ram;3.1.0 in central\n",
      "\tfound com.aliyun#aliyun-java-sdk-kms;2.11.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-azure-datalake;3.3.4 in central\n",
      "\tfound com.microsoft.azure#azure-data-lake-store-sdk;2.3.9 in central\n",
      "\tfound org.apache.hadoop#hadoop-openstack;3.3.4 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.54.v20240208 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.54.v20240208 in central\n",
      "\tfound io.delta#delta-spark_2.12;3.0.0 in central\n",
      "\tfound io.delta#delta-storage;3.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.3 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.3 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-aws;3.3.4!hadoop-aws.jar (202ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.12.262!aws-java-sdk-bundle.jar (46955ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-hadoop-cloud_2.12/3.5.3/spark-hadoop-cloud_2.12-3.5.3.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-hadoop-cloud_2.12;3.5.3!spark-hadoop-cloud_2.12.jar (90ms)\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/3.0.0/delta-spark_2.12-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-spark_2.12;3.0.0!delta-spark_2.12.jar (983ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.3/spark-sql-kafka-0-10_2.12-3.5.3.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.3!spark-sql-kafka-0-10_2.12.jar (93ms)\n",
      "downloading https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar ...\n",
      "\t[SUCCESSFUL ] org.wildfly.openssl#wildfly-openssl;1.0.7.Final!wildfly-openssl.jar (277ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.4!hadoop-client-runtime.jar (12642ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.2.14/gcs-connector-hadoop3-2.2.14-shaded.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud.bigdataoss#gcs-connector;hadoop3-2.2.14!gcs-connector.jar (15821ms)\n",
      "downloading https://repo1.maven.org/maven2/joda-time/joda-time/2.12.5/joda-time-2.12.5.jar ...\n",
      "\t[SUCCESSFUL ] joda-time#joda-time;2.12.5!joda-time.jar (278ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.15.2/jackson-databind-2.15.2.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-databind;2.15.2!jackson-databind.jar (716ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.15.2/jackson-annotations-2.15.2.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-annotations;2.15.2!jackson-annotations.jar (93ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.15.2/jackson-dataformat-cbor-2.15.2.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.15.2!jackson-dataformat-cbor.jar (84ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.14/httpclient-4.5.14.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.httpcomponents#httpclient;4.5.14!httpclient.jar (281ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.4.16/httpcore-4.4.16.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.httpcomponents#httpcore;4.4.16!httpcore.jar (184ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/3.3.4/hadoop-azure-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-azure;3.3.4!hadoop-azure.jar (207ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-cloud-storage/3.3.4/hadoop-cloud-storage-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-cloud-storage;3.3.4!hadoop-cloud-storage.jar (69ms)\n",
      "downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.54.v20240208/jetty-util-9.4.54.v20240208.jar ...\n",
      "\t[SUCCESSFUL ] org.eclipse.jetty#jetty-util;9.4.54.v20240208!jetty-util.jar (199ms)\n",
      "downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util-ajax/9.4.54.v20240208/jetty-util-ajax-9.4.54.v20240208.jar ...\n",
      "\t[SUCCESSFUL ] org.eclipse.jetty#jetty-util-ajax;9.4.54.v20240208!jetty-util-ajax.jar (88ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.4!hadoop-client-api.jar (5473ms)\n",
      "downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar ...\n",
      "\t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.5!snappy-java.jar(bundle) (382ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;2.0.7!slf4j-api.jar (68ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...\n",
      "\t[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (68ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (72ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.15.2/jackson-core-2.15.2.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-core;2.15.2!jackson-core.jar (1587ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.16.1/commons-codec-1.16.1.jar ...\n",
      "\t[SUCCESSFUL ] commons-codec#commons-codec;1.16.1!commons-codec.jar (407ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/azure-storage/7.0.1/azure-storage-7.0.1.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#azure-storage;7.0.1!azure-storage.jar (399ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1!hadoop-shaded-guava.jar (1273ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.9.13!jackson-mapper-asl.jar (338ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/azure-keyvault-core/1.0.0/azure-keyvault-core-1.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#azure-keyvault-core;1.0.0!azure-keyvault-core.jar (65ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/guava/guava/14.0.1/guava-14.0.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.guava#guava;14.0.1!guava.jar(bundle) (803ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;3.3.4!hadoop-annotations.jar (181ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aliyun/3.3.4/hadoop-aliyun-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-aliyun;3.3.4!hadoop-aliyun.jar (75ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure-datalake/3.3.4/hadoop-azure-datalake-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-azure-datalake;3.3.4!hadoop-azure-datalake.jar (68ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-openstack/3.3.4/hadoop-openstack-3.3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-openstack;3.3.4!hadoop-openstack.jar (95ms)\n",
      "downloading https://repo1.maven.org/maven2/com/aliyun/oss/aliyun-sdk-oss/3.13.0/aliyun-sdk-oss-3.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.aliyun.oss#aliyun-sdk-oss;3.13.0!aliyun-sdk-oss.jar (289ms)\n",
      "downloading https://repo1.maven.org/maven2/org/jdom/jdom2/2.0.6/jdom2-2.0.6.jar ...\n",
      "\t[SUCCESSFUL ] org.jdom#jdom2;2.0.6!jdom2.jar (200ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.jettison#jettison;1.1!jettison.jar(bundle) (129ms)\n",
      "downloading https://repo1.maven.org/maven2/com/aliyun/aliyun-java-sdk-core/4.5.10/aliyun-java-sdk-core-4.5.10.jar ...\n",
      "\t[SUCCESSFUL ] com.aliyun#aliyun-java-sdk-core;4.5.10!aliyun-java-sdk-core.jar (163ms)\n",
      "downloading https://repo1.maven.org/maven2/com/aliyun/aliyun-java-sdk-ram/3.1.0/aliyun-java-sdk-ram-3.1.0.jar ...\n",
      "\t[SUCCESSFUL ] com.aliyun#aliyun-java-sdk-ram;3.1.0!aliyun-java-sdk-ram.jar (106ms)\n",
      "downloading https://repo1.maven.org/maven2/com/aliyun/aliyun-java-sdk-kms/2.11.0/aliyun-java-sdk-kms-2.11.0.jar ...\n",
      "\t[SUCCESSFUL ] com.aliyun#aliyun-java-sdk-kms;2.11.0!aliyun-java-sdk-kms.jar (89ms)\n",
      "downloading https://repo1.maven.org/maven2/stax/stax-api/1.0.1/stax-api-1.0.1.jar ...\n",
      "\t[SUCCESSFUL ] stax#stax-api;1.0.1!stax-api.jar (69ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/gson/gson/2.8.9/gson-2.8.9.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.gson#gson;2.8.9!gson.jar (196ms)\n",
      "downloading https://repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar ...\n",
      "\t[SUCCESSFUL ] javax.xml.bind#jaxb-api;2.2.11!jaxb-api.jar (124ms)\n",
      "downloading https://repo1.maven.org/maven2/org/ini4j/ini4j/0.5.4/ini4j-0.5.4.jar ...\n",
      "\t[SUCCESSFUL ] org.ini4j#ini4j;0.5.4!ini4j.jar (107ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar ...\n",
      "\t[SUCCESSFUL ] io.opentracing#opentracing-api;0.33.0!opentracing-api.jar (64ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar ...\n",
      "\t[SUCCESSFUL ] io.opentracing#opentracing-util;0.33.0!opentracing-util.jar (67ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar ...\n",
      "\t[SUCCESSFUL ] io.opentracing#opentracing-noop;0.33.0!opentracing-noop.jar (140ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/azure/azure-data-lake-store-sdk/2.3.9/azure-data-lake-store-sdk-2.3.9.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.azure#azure-data-lake-store-sdk;2.3.9!azure-data-lake-store-sdk.jar (81ms)\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-storage/3.0.0/delta-storage-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-storage;3.0.0!delta-storage.jar (67ms)\n",
      "downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.9.3/antlr4-runtime-4.9.3.jar ...\n",
      "\t[SUCCESSFUL ] org.antlr#antlr4-runtime;4.9.3!antlr4-runtime.jar (116ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.3/spark-token-provider-kafka-0-10_2.12-3.5.3.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.3!spark-token-provider-kafka-0-10_2.12.jar (69ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.4.1/kafka-clients-3.4.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.kafka#kafka-clients;3.4.1!kafka-clients.jar (1523ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (83ms)\n",
      "downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...\n",
      "\t[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (191ms)\n",
      ":: resolution report :: resolve 35574ms :: artifacts dl 94681ms\n",
      "\t:: modules in use:\n",
      "\tcom.aliyun#aliyun-java-sdk-core;4.5.10 from central in [default]\n",
      "\tcom.aliyun#aliyun-java-sdk-kms;2.11.0 from central in [default]\n",
      "\tcom.aliyun#aliyun-java-sdk-ram;3.1.0 from central in [default]\n",
      "\tcom.aliyun.oss#aliyun-sdk-oss;3.13.0 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.15.2 from central in [default]\n",
      "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.15.2 from central in [default]\n",
      "\tcom.google.cloud.bigdataoss#gcs-connector;hadoop3-2.2.14 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.8.9 from central in [default]\n",
      "\tcom.google.guava#guava;14.0.1 from central in [default]\n",
      "\tcom.microsoft.azure#azure-data-lake-store-sdk;2.3.9 from central in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.0.0 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.16.1 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.0.0 from central in [default]\n",
      "\tio.opentracing#opentracing-api;0.33.0 from central in [default]\n",
      "\tio.opentracing#opentracing-noop;0.33.0 from central in [default]\n",
      "\tio.opentracing#opentracing-util;0.33.0 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.11 from central in [default]\n",
      "\tjoda-time#joda-time;2.12.5 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aliyun;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure-datalake;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-cloud-storage;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-openstack;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.14 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.16 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-hadoop-cloud_2.12;3.5.3 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.3 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.3 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.54.v20240208 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.54.v20240208 from central in [default]\n",
      "\torg.ini4j#ini4j;0.5.4 from central in [default]\n",
      "\torg.jdom#jdom2;2.0.6 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.5 from central in [default]\n",
      "\tstax#stax-api;1.0.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 by [org.eclipse.jetty#jetty-util-ajax;9.4.54.v20240208] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   55  |   54  |   54  |   1   ||   54  |   54  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f5492da6-1898-48e3-b9cb-92c2b00e3752\n",
      "\tconfs: [default]\n",
      "\t54 artifacts copied, 0 already retrieved (390169kB/370ms)\n",
      "26/01/23 13:33:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark Session 'StreamingBronze' configurÃ©e\n",
      "âœ… Output: s3a://datalake/bronze/flights\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType, BooleanType, LongType\n",
    "from config import get_s3_path, create_spark_session\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "KAFKA_BOOTSTRAP = os.getenv(\"KAFKA_BOOTSTRAP\", \"kafka1:9092\")\n",
    "TOPIC_NAME = os.getenv(\"TOPIC_NAME\", \"opensky-data\")\n",
    "BRONZE_PATH = get_s3_path(\"bronze\", \"flights\")\n",
    "CHECKPOINT_PATH = get_s3_path(\"checkpoints\", \"bronze_flights\")\n",
    "\n",
    "spark = create_spark_session(\"StreamingBronze\", extra_packages=[\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3\"])\n",
    "\n",
    "print(f\"âœ… Output: {BRONZE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchÃ©ma des donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:20:44.136482Z",
     "start_time": "2026-01-19T16:20:44.090573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SchÃ©ma dÃ©fini\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"time\", LongType(), True),\n",
    "    StructField(\"icao24\", StringType(), True),\n",
    "    StructField(\"callsign\", StringType(), True),\n",
    "    StructField(\"origin_country\", StringType(), True),\n",
    "    StructField(\"time_position\", LongType(), True),\n",
    "    StructField(\"last_contact\", LongType(), True),\n",
    "    StructField(\"longitude\", FloatType(), True),\n",
    "    StructField(\"latitude\", FloatType(), True),\n",
    "    StructField(\"baro_altitude\", FloatType(), True),\n",
    "    StructField(\"on_ground\", BooleanType(), True),\n",
    "    StructField(\"velocity\", FloatType(), True),\n",
    "    StructField(\"true_track\", FloatType(), True),\n",
    "    StructField(\"vertical_rate\", FloatType(), True),\n",
    "    StructField(\"geo_altitude\", FloatType(), True),\n",
    "    StructField(\"squawk\", StringType(), True),\n",
    "    StructField(\"spi\", BooleanType(), True),\n",
    "    StructField(\"position_source\", IntegerType(), True),\n",
    "    StructField(\"category\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "print(\"âœ… SchÃ©ma dÃ©fini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Kafka â†’ Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:21:47.885288Z",
     "start_time": "2026-01-19T16:20:51.265953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Streaming vers s3a://datalake/bronze/flights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 14:07:58 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "26/01/23 14:07:58 WARN StreamingQueryManager: Stopping existing streaming query [id=00581bd0-e6af-4af7-b49c-64568b446ba4, runId=6d4927a3-f9ab-45b7-9dde-9d38f754cb5a], as a new run is being started.\n",
      "26/01/23 14:07:58 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "26/01/23 14:12:57 ERROR NonFateSharingFuture: Failed to get result from future  \n",
      "scala.runtime.NonLocalReturnControl\n",
      "ERROR:root:KeyboardInterrupt while sending command.                             \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/socket.py\", line 720, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸš€ Streaming vers \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBRONZE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m query = parsed_df.writeStream \\\n\u001b[32m     16\u001b[39m     .format(\u001b[33m\"\u001b[39m\u001b[33mdelta\u001b[39m\u001b[33m\"\u001b[39m) \\\n\u001b[32m     17\u001b[39m     .outputMode(\u001b[33m\"\u001b[39m\u001b[33mappend\u001b[39m\u001b[33m\"\u001b[39m) \\\n\u001b[32m     18\u001b[39m     .option(\u001b[33m\"\u001b[39m\u001b[33mcheckpointLocation\u001b[39m\u001b[33m\"\u001b[39m, CHECKPOINT_PATH) \\\n\u001b[32m     19\u001b[39m     .start(BRONZE_PATH)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pyspark/sql/streaming/query.py:221\u001b[39m, in \u001b[36mStreamingQuery.awaitTermination\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jsq.awaitTermination(\u001b[38;5;28mint\u001b[39m(timeout * \u001b[32m1000\u001b[39m))\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jsq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/py4j/java_gateway.py:1321\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1314\u001b[39m args_command, temp_args = \u001b[38;5;28mself\u001b[39m._build_args(*args)\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m-> \u001b[39m\u001b[32m1321\u001b[39m answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1322\u001b[39m return_value = get_return_value(\n\u001b[32m   1323\u001b[39m     answer, \u001b[38;5;28mself\u001b[39m.gateway_client, \u001b[38;5;28mself\u001b[39m.target_id, \u001b[38;5;28mself\u001b[39m.name)\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/py4j/java_gateway.py:1038\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1036\u001b[39m connection = \u001b[38;5;28mself\u001b[39m._get_connection()\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[32m   1040\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m._create_connection_guard(connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/py4j/clientserver.py:511\u001b[39m, in \u001b[36mClientServerConnection.send_command\u001b[39m\u001b[34m(self, command)\u001b[39m\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    510\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m         answer = smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:-\u001b[32m1\u001b[39m])\n\u001b[32m    512\u001b[39m         logger.debug(\u001b[33m\"\u001b[39m\u001b[33mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m\"\u001b[39m.format(answer))\n\u001b[32m    513\u001b[39m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[32m    514\u001b[39m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "kafka_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BOOTSTRAP) \\\n",
    "    .option(\"subscribe\", TOPIC_NAME) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .load()\n",
    "\n",
    "parsed_df = kafka_df.select(\n",
    "    from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\")\n",
    ").select(\"data.*\")\n",
    "\n",
    "print(f\"ðŸš€ Streaming vers {BRONZE_PATH}...\")\n",
    "\n",
    "query = parsed_df.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", CHECKPOINT_PATH) \\\n",
    "    .start(BRONZE_PATH)\n",
    "\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
