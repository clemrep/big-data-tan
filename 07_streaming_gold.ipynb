{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# 07 - Streaming Gold\n\nAgrégations temps réel avec fenêtres temporelles sur les données Silver.\n\n**Requêtes implémentées:**\n1. **Comptage par phase de vol** - Tumbling window 1 minute\n2. **Alertes anomalies** - Sliding window 5 minutes (slide 1 min)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-2",
   "metadata": {},
   "source": "from pyspark.sql.functions import (\n    col, window, count, avg, stddev, max as spark_max, min as spark_min,\n    when, lit, current_timestamp\n)\nfrom config import get_s3_path, create_spark_session\n\nSILVER_PATH = get_s3_path(\"silver\", \"flights\")\nGOLD_COUNTRY_STATS_PATH = get_s3_path(\"gold\", \"country_stats\")\nGOLD_COUNTRY_ANOMALIES_PATH = get_s3_path(\"gold\", \"country_anomalies\")\nCHECKPOINT_COUNTRY_STATS = get_s3_path(\"checkpoints\", \"gold_country_stats\")\nCHECKPOINT_COUNTRY_ANOMALIES = get_s3_path(\"checkpoints\", \"gold_country_anomalies\")\n\nspark = create_spark_session(\"StreamingGold\")\n\nprint(f\"Input:  {SILVER_PATH}\")\nprint(f\"Output Country Stats:    {GOLD_COUNTRY_STATS_PATH}\")\nprint(f\"Output Country Anomalies: {GOLD_COUNTRY_ANOMALIES_PATH}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": "## Lecture du stream Silver"
  },
  {
   "cell_type": "code",
   "id": "cell-4",
   "metadata": {},
   "source": "df_silver_stream = spark.readStream \\\n    .format(\"delta\") \\\n    .load(SILVER_PATH)\n\nprint(f\"Stream Silver initialisé\")\nprint(f\"Colonnes: {df_silver_stream.columns}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": "## Stream 1 : Statistiques par pays (Tumbling Window 1 min)\n\nAgrégation temps réel des statistiques de vol par pays d'origine avec une fenêtre tumbling de 1 minute."
  },
  {
   "cell_type": "code",
   "id": "cell-6",
   "metadata": {},
   "source": "df_country_stats = df_silver_stream \\\n    .withWatermark(\"event_timestamp\", \"2 minutes\") \\\n    .groupBy(\n        window(col(\"event_timestamp\"), \"1 minute\"),\n        col(\"origin_country\")\n    ) \\\n    .agg(\n        count(\"*\").alias(\"flight_count\"),\n        avg(\"altitude_meters\").alias(\"avg_altitude\"),\n        avg(\"velocity_kmh\").alias(\"avg_velocity\"),\n        count(when(col(\"on_ground\") == True, 1)).alias(\"ground_count\"),\n        count(when(col(\"on_ground\") == False, 1)).alias(\"airborne_count\")\n    ) \\\n    .select(\n        col(\"window.start\").alias(\"window_start\"),\n        col(\"window.end\").alias(\"window_end\"),\n        col(\"origin_country\"),\n        col(\"flight_count\"),\n        col(\"avg_altitude\"),\n        col(\"avg_velocity\"),\n        col(\"ground_count\"),\n        col(\"airborne_count\")\n    )\n\nprint(\"Stream 1: Statistiques par pays (Tumbling Window 1 min)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-7",
   "metadata": {},
   "source": "query_country_stats = df_country_stats.writeStream \\\n    .format(\"delta\") \\\n    .outputMode(\"append\") \\\n    .option(\"checkpointLocation\", CHECKPOINT_COUNTRY_STATS) \\\n    .start(GOLD_COUNTRY_STATS_PATH)\n\nprint(f\"Stream 1 démarré -> {GOLD_COUNTRY_STATS_PATH}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Stream 2 : Alertes anomalies par pays (Sliding Window 5 min, slide 1 min)\n",
    "\n",
    "Détection de vitesses et altitudes anormales par pays d'origine avec une fenêtre glissante de 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-9",
   "metadata": {},
   "source": "# Supprimé - fusionné avec la cellule suivante",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-10",
   "metadata": {},
   "source": "# Seuils d'anomalie\nALTITUDE_MAX_THRESHOLD = 12000  # mètres\nVELOCITY_MAX_THRESHOLD = 1000   # km/h\nALTITUDE_MIN_THRESHOLD = -100   # mètres (sous le niveau de la mer)\nVELOCITY_MIN_THRESHOLD = 0      # km/h\n\nprint(f\"Seuils d'anomalie:\")\nprint(f\"  Altitude: {ALTITUDE_MIN_THRESHOLD}m - {ALTITUDE_MAX_THRESHOLD}m\")\nprint(f\"  Vitesse:  {VELOCITY_MIN_THRESHOLD} - {VELOCITY_MAX_THRESHOLD} km/h\")\n\n# Relecture du stream pour le second pipeline\ndf_silver_stream_2 = spark.readStream \\\n    .format(\"delta\") \\\n    .load(SILVER_PATH)\n\ndf_anomalies = df_silver_stream_2 \\\n    .withColumn(\n        \"is_altitude_anomaly\",\n        when(\n            (col(\"altitude_meters\") > ALTITUDE_MAX_THRESHOLD) | \n            (col(\"altitude_meters\") < ALTITUDE_MIN_THRESHOLD),\n            1\n        ).otherwise(0)\n    ) \\\n    .withColumn(\n        \"is_velocity_anomaly\",\n        when(\n            (col(\"velocity_kmh\") > VELOCITY_MAX_THRESHOLD) | \n            (col(\"velocity_kmh\") < VELOCITY_MIN_THRESHOLD),\n            1\n        ).otherwise(0)\n    ) \\\n    .withWatermark(\"event_timestamp\", \"6 minutes\") \\\n    .groupBy(\n        window(col(\"event_timestamp\"), \"5 minutes\", \"1 minute\"),\n        col(\"origin_country\")\n    ) \\\n    .agg(\n        count(\"*\").alias(\"total_observations\"),\n        count(when(col(\"is_altitude_anomaly\") == 1, 1)).alias(\"altitude_anomalies\"),\n        count(when(col(\"is_velocity_anomaly\") == 1, 1)).alias(\"velocity_anomalies\"),\n        spark_max(\"altitude_meters\").alias(\"max_altitude\"),\n        spark_min(\"altitude_meters\").alias(\"min_altitude\"),\n        spark_max(\"velocity_kmh\").alias(\"max_velocity\"),\n        avg(\"altitude_meters\").alias(\"avg_altitude\"),\n        avg(\"velocity_kmh\").alias(\"avg_velocity\"),\n        stddev(\"altitude_meters\").alias(\"stddev_altitude\"),\n        stddev(\"velocity_kmh\").alias(\"stddev_velocity\")\n    ) \\\n    .withColumn(\n        \"anomaly_rate\",\n        (col(\"altitude_anomalies\") + col(\"velocity_anomalies\")) / col(\"total_observations\")\n    ) \\\n    .select(\n        col(\"window.start\").alias(\"window_start\"),\n        col(\"window.end\").alias(\"window_end\"),\n        col(\"origin_country\"),\n        col(\"total_observations\"),\n        col(\"altitude_anomalies\"),\n        col(\"velocity_anomalies\"),\n        col(\"anomaly_rate\"),\n        col(\"max_altitude\"),\n        col(\"min_altitude\"),\n        col(\"max_velocity\"),\n        col(\"avg_altitude\"),\n        col(\"avg_velocity\"),\n        col(\"stddev_altitude\"),\n        col(\"stddev_velocity\")\n    )\n\nprint(\"Stream 2: Alertes anomalies par pays (Sliding Window 5 min)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-11",
   "metadata": {},
   "source": "query_country_anomalies = df_anomalies.writeStream \\\n    .format(\"delta\") \\\n    .outputMode(\"append\") \\\n    .option(\"checkpointLocation\", CHECKPOINT_COUNTRY_ANOMALIES) \\\n    .start(GOLD_COUNTRY_ANOMALIES_PATH)\n\nprint(f\"Stream 2 démarré -> {GOLD_COUNTRY_ANOMALIES_PATH}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Monitoring des streams"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-13",
   "metadata": {},
   "source": "import time\n\nprint(\"Monitoring des streams Gold (Ctrl+C pour arrêter)\")\nprint(\"=\" * 60)\n\ntry:\n    while True:\n        print(f\"\\n{time.strftime('%H:%M:%S')}\")\n        print(f\"  Country Stats:    {query_country_stats.status}\")\n        print(f\"  Country Anomalies: {query_country_anomalies.status}\")\n        time.sleep(30)\nexcept KeyboardInterrupt:\n    print(\"\\nArrêt demandé...\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Arrêt des streams"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-15",
   "metadata": {},
   "source": "query_country_stats.stop()\nquery_country_anomalies.stop()\nprint(\"Tous les streams Gold arrêtés\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Vérification des données Gold"
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-17",
   "metadata": {},
   "source": "print(\"Statistiques Gold:\")\n\ntry:\n    df_stats = spark.read.format(\"delta\").load(GOLD_COUNTRY_STATS_PATH)\n    print(f\"  Country Stats: {df_stats.count():,} lignes\")\n    print(\"\\n  Dernières statistiques par pays:\")\n    df_stats.orderBy(col(\"window_start\").desc()).limit(10).show(truncate=False)\nexcept Exception as e:\n    print(f\"  Country Stats: Table non disponible ({e})\")\n\ntry:\n    df_anom = spark.read.format(\"delta\").load(GOLD_COUNTRY_ANOMALIES_PATH)\n    print(f\"\\n  Country Anomalies: {df_anom.count():,} lignes\")\n    print(\"\\n  Pays avec le plus d'anomalies:\")\n    df_anom.filter(col(\"anomaly_rate\") > 0) \\\n        .orderBy(col(\"anomaly_rate\").desc()) \\\n        .limit(10).show(truncate=False)\nexcept Exception as e:\n    print(f\"  Country Anomalies: Table non disponible ({e})\")",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}