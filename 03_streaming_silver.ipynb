{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Streaming Silver & Silver_ML\n",
    "\n",
    "Pipeline de transformation :\n",
    "- **Bronze ‚Üí Silver** : Nettoyage et enrichissement\n",
    "- **Bronze ‚Üí Silver_ML** : Feature engineering pour le Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:25:22.327108Z",
     "start_time": "2026-01-19T16:25:22.019412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark Session 'StreamingSilver' configur√©e\n",
      "‚úÖ Input:     s3a://datalake/bronze/flights\n",
      "‚úÖ Silver:    s3a://datalake/silver/flights\n",
      "‚úÖ Silver_ML: s3a://datalake/silver/flights_ml\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, from_unixtime, to_timestamp, round,\n",
    "    lag, avg, stddev, row_number, when, sqrt, pow, lit, min as spark_min, broadcast\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "from config import get_s3_path, create_spark_session\n",
    "\n",
    "BRONZE_PATH = get_s3_path(\"bronze\", \"flights\")\n",
    "SILVER_PATH = get_s3_path(\"silver\", \"flights\")\n",
    "SILVER_ML_PATH = get_s3_path(\"silver\", \"flights_ml\")\n",
    "CHECKPOINT_SILVER = get_s3_path(\"checkpoints\", \"silver_flights\")\n",
    "CHECKPOINT_SILVER_ML = get_s3_path(\"checkpoints\", \"silver_ml_flights\")\n",
    "AIRPORTS_CSV = \"./data/airports.csv\"\n",
    "\n",
    "spark = create_spark_session(\"StreamingSilver\")\n",
    "\n",
    "print(f\"‚úÖ Input:     {BRONZE_PATH}\")\n",
    "print(f\"‚úÖ Silver:    {SILVER_PATH}\")\n",
    "print(f\"‚úÖ Silver_ML: {SILVER_ML_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des donn√©es a√©roports (pour Silver_ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:26:09.818721Z",
     "start_time": "2026-01-19T16:25:58.766040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 5211 a√©roports charg√©s\n"
     ]
    }
   ],
   "source": [
    "df_airports = spark.read.option(\"header\", \"true\").csv(AIRPORTS_CSV).select(\n",
    "    col(\"ident\").alias(\"airport_icao\"),\n",
    "    col(\"name\").alias(\"airport_name\"),\n",
    "    col(\"iso_country\").alias(\"airport_country\"),\n",
    "    col(\"latitude_deg\").cast(\"double\").alias(\"airport_lat\"),\n",
    "    col(\"longitude_deg\").cast(\"double\").alias(\"airport_lon\")\n",
    ").filter(col(\"type\").isin(\"large_airport\", \"medium_airport\"))\n",
    "\n",
    "print(f\"‚úÖ {df_airports.count()} a√©roports charg√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream 1 : Bronze ‚Üí Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:26:10.624729Z",
     "start_time": "2026-01-19T16:26:09.823686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Stream 1: Bronze ‚Üí Silver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:38:16 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "26/01/23 15:38:16 WARN StreamingQueryManager: Stopping existing streaming query [id=03cb7525-313b-4658-807f-c1584735ae56, runId=1af062d8-10ee-4697-b766-c1f13030c8bb], as a new run is being started.\n",
      "26/01/23 15:38:16 ERROR TorrentBroadcast: Store broadcast broadcast_608 fail, remove all pieces of the broadcast\n"
     ]
    }
   ],
   "source": [
    "df_bronze_stream = spark.readStream.format(\"delta\").load(BRONZE_PATH)\n",
    "\n",
    "df_silver = df_bronze_stream \\\n",
    "    .filter(col(\"icao24\").isNotNull()) \\\n",
    "    .filter(col(\"latitude\").isNotNull() & col(\"longitude\").isNotNull()) \\\n",
    "    .withColumn(\"event_timestamp\", to_timestamp(from_unixtime(col(\"time\")))) \\\n",
    "    .withColumn(\"velocity_kmh\", round(col(\"velocity\") * 3.6, 2)) \\\n",
    "    .withColumn(\"altitude_meters\", col(\"baro_altitude\")) \\\n",
    "    .select(\n",
    "        \"event_timestamp\", \"icao24\", \"callsign\", \"origin_country\",\n",
    "        \"longitude\", \"latitude\", \"velocity_kmh\", \"altitude_meters\",\n",
    "        \"on_ground\", \"category\"\n",
    "    )\n",
    "\n",
    "print(f\"üöÄ Stream 1: Bronze ‚Üí Silver\")\n",
    "\n",
    "query_silver = df_silver.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"checkpointLocation\", CHECKPOINT_SILVER) \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .start(SILVER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream 2 : Bronze ‚Üí Silver_ML (Feature Engineering)\n",
    "\n",
    "Transformation avec features pour le ML, directement depuis Bronze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:24:55.935373Z",
     "start_time": "2026-01-19T16:24:55.818025Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_ml_batch(batch_df, batch_id):\n",
    "    \"\"\"Traitement d'un micro-batch pour Silver_ML avec feature engineering.\"\"\"\n",
    "    \n",
    "    if batch_df.isEmpty():\n",
    "        return\n",
    "    \n",
    "    # Transformation Bronze ‚Üí format Silver\n",
    "    df_base = batch_df \\\n",
    "        .filter(col(\"icao24\").isNotNull()) \\\n",
    "        .filter(col(\"latitude\").isNotNull() & col(\"longitude\").isNotNull()) \\\n",
    "        .withColumn(\"event_timestamp\", to_timestamp(from_unixtime(col(\"time\")))) \\\n",
    "        .withColumn(\"velocity_kmh\", round(col(\"velocity\") * 3.6, 2)) \\\n",
    "        .withColumn(\"altitude_meters\", col(\"baro_altitude\"))\n",
    "    \n",
    "    # Nettoyage ML\n",
    "    df_clean = df_base \\\n",
    "        .filter(col(\"altitude_meters\").between(-500, 15000)) \\\n",
    "        .filter(col(\"velocity_kmh\").between(0, 1200))\n",
    "    \n",
    "    if df_clean.isEmpty():\n",
    "        return\n",
    "    \n",
    "    # Features temporelles\n",
    "    window_aircraft = Window.partitionBy(\"icao24\").orderBy(\"event_timestamp\")\n",
    "    \n",
    "    df_temporal = df_clean \\\n",
    "        .withColumn(\"prev_altitude\", lag(\"altitude_meters\", 1).over(window_aircraft)) \\\n",
    "        .withColumn(\"prev_velocity\", lag(\"velocity_kmh\", 1).over(window_aircraft)) \\\n",
    "        .withColumn(\"altitude_change\", col(\"altitude_meters\") - col(\"prev_altitude\")) \\\n",
    "        .withColumn(\"velocity_change\", col(\"velocity_kmh\") - col(\"prev_velocity\")) \\\n",
    "        .withColumn(\"observation_rank\", row_number().over(window_aircraft))\n",
    "    \n",
    "    # Jointure a√©roports\n",
    "    df_on_ground = df_temporal.filter(col(\"on_ground\") == True)\n",
    "    df_in_flight = df_temporal.filter(col(\"on_ground\") == False)\n",
    "    \n",
    "    if df_on_ground.count() > 0:\n",
    "        df_with_airports = df_on_ground.crossJoin(broadcast(df_airports)).withColumn(\n",
    "            \"dist\", sqrt(pow(col(\"latitude\") - col(\"airport_lat\"), 2) + pow(col(\"longitude\") - col(\"airport_lon\"), 2))\n",
    "        )\n",
    "        \n",
    "        w = Window.partitionBy(\"icao24\", \"event_timestamp\")\n",
    "        df_closest = df_with_airports.withColumn(\"min_dist\", spark_min(\"dist\").over(w)) \\\n",
    "            .filter(col(\"dist\") == col(\"min_dist\")) \\\n",
    "            .drop(\"dist\", \"min_dist\", \"airport_lat\", \"airport_lon\")\n",
    "        \n",
    "        df_enriched = df_closest.unionByName(\n",
    "            df_in_flight.withColumn(\"airport_icao\", lit(None))\n",
    "                        .withColumn(\"airport_name\", lit(None))\n",
    "                        .withColumn(\"airport_country\", lit(None)),\n",
    "            allowMissingColumns=True\n",
    "        )\n",
    "    else:\n",
    "        df_enriched = df_in_flight \\\n",
    "            .withColumn(\"airport_icao\", lit(None)) \\\n",
    "            .withColumn(\"airport_name\", lit(None)) \\\n",
    "            .withColumn(\"airport_country\", lit(None))\n",
    "    \n",
    "    # Features rolling window\n",
    "    rolling_window = Window.partitionBy(\"icao24\").orderBy(\"event_timestamp\").rowsBetween(-5, 0)\n",
    "    \n",
    "    df_rolling = df_enriched \\\n",
    "        .withColumn(\"rolling_avg_altitude\", avg(\"altitude_meters\").over(rolling_window)) \\\n",
    "        .withColumn(\"rolling_std_altitude\", stddev(\"altitude_meters\").over(rolling_window)) \\\n",
    "        .withColumn(\"rolling_avg_velocity\", avg(\"velocity_kmh\").over(rolling_window))\n",
    "    \n",
    "    # Label flight_phase\n",
    "    df_ml = df_rolling.withColumn(\n",
    "        \"flight_phase\",\n",
    "        when(col(\"on_ground\") == True, \"GROUND\")\n",
    "        .when((col(\"altitude_change\") > 50) & (col(\"altitude_meters\") < 3000), \"TAKEOFF\")\n",
    "        .when(col(\"altitude_change\") > 20, \"CLIMB\")\n",
    "        .when(col(\"altitude_change\").between(-20, 20) & (col(\"altitude_meters\") > 8000), \"CRUISE\")\n",
    "        .when(col(\"altitude_change\") < -20, \"DESCENT\")\n",
    "        .otherwise(\"TRANSITION\")\n",
    "    )\n",
    "    \n",
    "    # S√©lection des colonnes finales\n",
    "    df_final = df_ml.select(\n",
    "        \"event_timestamp\", \"icao24\", \"callsign\", \"origin_country\",\n",
    "        \"longitude\", \"latitude\", \"velocity_kmh\", \"altitude_meters\",\n",
    "        \"on_ground\", \"category\",\n",
    "        \"prev_altitude\", \"prev_velocity\", \"altitude_change\", \"velocity_change\", \"observation_rank\",\n",
    "        \"airport_icao\", \"airport_name\", \"airport_country\",\n",
    "        \"rolling_avg_altitude\", \"rolling_std_altitude\", \"rolling_avg_velocity\",\n",
    "        \"flight_phase\"\n",
    "    )\n",
    "    \n",
    "    # √âcriture\n",
    "    df_final.write.format(\"delta\").mode(\"append\").save(SILVER_ML_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T16:25:12.757910Z",
     "start_time": "2026-01-19T16:25:08.640557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Stream 2: Bronze ‚Üí Silver_ML (Feature Engineering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:38:26 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_bronze_ml_stream = spark.readStream.format(\"delta\").load(BRONZE_PATH)\n",
    "\n",
    "print(f\"üöÄ Stream 2: Bronze ‚Üí Silver_ML (Feature Engineering)\")\n",
    "\n",
    "query_silver_ml = df_bronze_ml_stream.writeStream \\\n",
    "    .foreachBatch(process_ml_batch) \\\n",
    "    .option(\"checkpointLocation\", CHECKPOINT_SILVER_ML) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring des streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Monitoring des streams (Ctrl+C pour arr√™ter)\n",
      "============================================================\n",
      "\n",
      "‚è±Ô∏è  15:38:32\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:38:39 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:38:57 ERROR NonFateSharingFuture: Failed to get result from future  \n",
      "scala.runtime.NonLocalReturnControl\n",
      "26/01/23 15:39:00 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:39:02\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:39:15 ERROR NonFateSharingFuture: Failed to get result from future  \n",
      "scala.runtime.NonLocalReturnControl\n",
      "26/01/23 15:39:23 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:39:32\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:40:02\n",
      "  Silver:    {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:40:03 WARN S3AInstrumentation: Closing output stream statistics while data is still marked as pending upload in OutputStreamStatistics{counters=((op_abort=0) (stream_write_exceptions_completing_upload=0) (action_executor_acquired.failures=0) (object_multipart_aborted=0) (stream_write_total_data=0) (stream_write_total_time=0) (op_hflush=0) (object_multipart_aborted.failures=0) (stream_write_block_uploads=1) (multipart_upload_completed=0) (stream_write_queue_duration=0) (multipart_upload_completed.failures=0) (stream_write_exceptions=0) (op_hsync=0) (op_abort.failures=0) (action_executor_acquired=0) (stream_write_bytes=43468));\n",
      "gauges=((stream_write_block_uploads_data_pending=43468) (stream_write_block_uploads_pending=1));\n",
      "minimums=((multipart_upload_completed.min=-1) (object_multipart_aborted.failures.min=-1) (action_executor_acquired.min=-1) (multipart_upload_completed.failures.min=-1) (op_abort.failures.min=-1) (op_abort.min=-1) (action_executor_acquired.failures.min=-1) (object_multipart_aborted.min=-1));\n",
      "maximums=((action_executor_acquired.max=-1) (multipart_upload_completed.max=-1) (object_multipart_aborted.max=-1) (object_multipart_aborted.failures.max=-1) (action_executor_acquired.failures.max=-1) (multipart_upload_completed.failures.max=-1) (op_abort.max=-1) (op_abort.failures.max=-1));\n",
      "means=((object_multipart_aborted.mean=(samples=0, sum=0, mean=0.0000)) (op_abort.failures.mean=(samples=0, sum=0, mean=0.0000)) (op_abort.mean=(samples=0, sum=0, mean=0.0000)) (action_executor_acquired.mean=(samples=0, sum=0, mean=0.0000)) (action_executor_acquired.failures.mean=(samples=0, sum=0, mean=0.0000)) (multipart_upload_completed.failures.mean=(samples=0, sum=0, mean=0.0000)) (object_multipart_aborted.failures.mean=(samples=0, sum=0, mean=0.0000)) (multipart_upload_completed.mean=(samples=0, sum=0, mean=0.0000)));\n",
      ", blocksActive=0, blockUploadsCompleted=0, blocksAllocated=1, blocksReleased=1, blocksActivelyAllocated=0, transferDuration=0 ms, totalUploadDuration=0 ms, effectiveBandwidth=0.0 bytes/s}\n",
      "26/01/23 15:40:03 WARN S3AInstrumentation: Closing output stream statistics while data is still marked as pending upload in OutputStreamStatistics{counters=((action_executor_acquired.failures=0) (stream_write_total_data=0) (stream_write_total_time=0) (op_hsync=0) (op_abort=0) (object_multipart_aborted=0) (op_abort.failures=0) (stream_write_exceptions_completing_upload=0) (stream_write_block_uploads=1) (stream_write_exceptions=0) (stream_write_bytes=42350) (stream_write_queue_duration=0) (object_multipart_aborted.failures=0) (action_executor_acquired=0) (multipart_upload_completed=0) (op_hflush=0) (multipart_upload_completed.failures=0));\n",
      "gauges=((stream_write_block_uploads_pending=1) (stream_write_block_uploads_data_pending=42350));\n",
      "minimums=((action_executor_acquired.min=-1) (multipart_upload_completed.min=-1) (multipart_upload_completed.failures.min=-1) (op_abort.min=-1) (object_multipart_aborted.failures.min=-1) (object_multipart_aborted.min=-1) (op_abort.failures.min=-1) (action_executor_acquired.failures.min=-1));\n",
      "maximums=((op_abort.max=-1) (action_executor_acquired.max=-1) (object_multipart_aborted.max=-1) (op_abort.failures.max=-1) (action_executor_acquired.failures.max=-1) (multipart_upload_completed.max=-1) (object_multipart_aborted.failures.max=-1) (multipart_upload_completed.failures.max=-1));\n",
      "means=((op_abort.failures.mean=(samples=0, sum=0, mean=0.0000)) (op_abort.mean=(samples=0, sum=0, mean=0.0000)) (multipart_upload_completed.mean=(samples=0, sum=0, mean=0.0000)) (multipart_upload_completed.failures.mean=(samples=0, sum=0, mean=0.0000)) (action_executor_acquired.failures.mean=(samples=0, sum=0, mean=0.0000)) (object_multipart_aborted.mean=(samples=0, sum=0, mean=0.0000)) (action_executor_acquired.mean=(samples=0, sum=0, mean=0.0000)) (object_multipart_aborted.failures.mean=(samples=0, sum=0, mean=0.0000)));\n",
      ", blocksActive=0, blockUploadsCompleted=0, blocksAllocated=1, blocksReleased=1, blocksActivelyAllocated=0, transferDuration=0 ms, totalUploadDuration=0 ms, effectiveBandwidth=0.0 bytes/s}\n",
      "26/01/23 15:40:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:40:30 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:40:32\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:40:32 ERROR NonFateSharingFuture: Failed to get result from future\n",
      "scala.runtime.NonLocalReturnControl\n",
      "26/01/23 15:40:47 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:40:58 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "[Stage 555:==============>(47 + 3) / 50][Stage 557:==========>      (3 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:41:02\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:41:07 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:41:19 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:41:21 ERROR NonFateSharingFuture: Failed to get result from future  \n",
      "scala.runtime.NonLocalReturnControl\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:41:32\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:41:35 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:41:43 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:41:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:42:00 ERROR NonFateSharingFuture: Failed to get result from future  \n",
      "scala.runtime.NonLocalReturnControl\n",
      "[Stage 670:==>             (8 + 8) / 50][Stage 673:>               (0 + 0) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:42:02\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:42:07 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:42:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:42:27 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:42:32\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 763:===================================>                   (32 + 8) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:43:02\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:43:16 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:43:17 ERROR NonFateSharingFuture: Failed to get result from future  \n",
      "scala.runtime.NonLocalReturnControl\n",
      "26/01/23 15:43:30 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:43:33\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:43:52 ERROR NonFateSharingFuture: Failed to get result from future  \n",
      "scala.runtime.NonLocalReturnControl\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:44:03\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:44:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:44:10 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:44:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:44:33\n",
      "  Silver:    {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:44:54 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "[Stage 937:========>      (29 + 8) / 50][Stage 940:>               (0 + 0) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:45:03\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:45:33\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:45:41 ERROR NonFateSharingFuture: Failed to get result from future  \n",
      "scala.runtime.NonLocalReturnControl\n",
      "26/01/23 15:45:41 ERROR NonFateSharingFuture: Failed to get result from future\n",
      "scala.runtime.NonLocalReturnControl\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:46:03\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1033:>                                                      (0 + 8) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:46:33\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:47:02 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "[Stage 1053:=================================>                     (6 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:47:03\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:47:33\n",
      "  Silver:    {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:47:43 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "[Stage 1087:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:48:04\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:48:16 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:48:35\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:48:48 ERROR NonFateSharingFuture: Failed to get result from future  \n",
      "scala.runtime.NonLocalReturnControl\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:49:05\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1139:============================>                           (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:49:35\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1149:>                                                       (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:50:05\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1160:>              (0 + 8) / 20][Stage 1162:>               (0 + 0) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:50:35\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1166:=========>    (33 + 8) / 50][Stage 1169:==>            (8 + 0) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:51:06\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1178:=================================>                     (6 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:51:36\n",
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1192:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:52:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Silver:    {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/23 15:52:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "26/01/23 15:52:22 ERROR NonFateSharingFuture: Failed to get result from future  \n",
      "scala.runtime.NonLocalReturnControl\n",
      "[Stage 1211:====================================================> (49 + 1) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:52:36\n",
      "  Silver:    {'message': 'Waiting for data to arrive', 'isDataAvailable': False, 'isTriggerActive': False}\n",
      "  Silver_ML: {'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  15:53:06\n",
      "  Silver:    {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "\n",
      "‚è±Ô∏è  15:53:36\n",
      "  Silver:    {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "\n",
      "‚è±Ô∏è  15:54:06\n",
      "  Silver:    {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "\n",
      "‚è±Ô∏è  15:54:36\n",
      "  Silver:    {'message': 'Waiting for data to arrive', 'isDataAvailable': False, 'isTriggerActive': False}\n",
      "  Silver_ML: {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "\n",
      "‚è±Ô∏è  15:55:06\n",
      "  Silver:    {'message': 'Waiting for data to arrive', 'isDataAvailable': False, 'isTriggerActive': False}\n",
      "  Silver_ML: {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "\n",
      "‚è±Ô∏è  15:55:36\n",
      "  Silver:    {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Waiting for data to arrive', 'isDataAvailable': False, 'isTriggerActive': False}\n",
      "\n",
      "‚è±Ô∏è  15:56:06\n",
      "  Silver:    {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Waiting for data to arrive', 'isDataAvailable': False, 'isTriggerActive': False}\n",
      "\n",
      "‚è±Ô∏è  15:56:36\n",
      "  Silver:    {'message': 'Getting offsets from DeltaSource[s3a://datalake/bronze/flights]', 'isDataAvailable': False, 'isTriggerActive': True}\n",
      "  Silver_ML: {'message': 'Waiting for data to arrive', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"üìä Monitoring des streams (Ctrl+C pour arr√™ter)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        print(f\"\\n‚è±Ô∏è  {time.strftime('%H:%M:%S')}\")\n",
    "        print(f\"  Silver:    {query_silver.status}\")\n",
    "        print(f\"  Silver_ML: {query_silver_ml.status}\")\n",
    "        time.sleep(30)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚èπÔ∏è  Arr√™t demand√©...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arr√™t des streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tous les streams arr√™t√©s\n"
     ]
    }
   ],
   "source": [
    "query_silver.stop()\n",
    "query_silver_ml.stop()\n",
    "print(\"‚úÖ Tous les streams arr√™t√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V√©rification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Statistiques :\n",
      "  Bronze:    98,840 lignes\n",
      "  Silver:    97,950 lignes\n",
      "  Silver_ML: 88,432 lignes\n",
      "\n",
      "üìä Distribution flight_phase (Silver_ML) :\n",
      "+------------+-----+\n",
      "|flight_phase|count|\n",
      "+------------+-----+\n",
      "|      CRUISE|37190|\n",
      "|  TRANSITION|29374|\n",
      "|     DESCENT|10699|\n",
      "|       CLIMB| 8877|\n",
      "|     TAKEOFF| 2035|\n",
      "|      GROUND|  257|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Statistiques :\")\n",
    "print(f\"  Bronze:    {spark.read.format('delta').load(BRONZE_PATH).count():,} lignes\")\n",
    "print(f\"  Silver:    {spark.read.format('delta').load(SILVER_PATH).count():,} lignes\")\n",
    "print(f\"  Silver_ML: {spark.read.format('delta').load(SILVER_ML_PATH).count():,} lignes\")\n",
    "\n",
    "print(\"\\nüìä Distribution flight_phase (Silver_ML) :\")\n",
    "spark.read.format(\"delta\").load(SILVER_ML_PATH).groupBy(\"flight_phase\").count().orderBy(\"count\", ascending=False).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
